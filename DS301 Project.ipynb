{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object here is to train a machine learning model on a database of Tweets and use that model to predict sentiment of Tweets from a user, a hashtag, or any random variety of Tweets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@author Ryan Herren\n",
    "@author Tanner Dunn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ryanherren/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator \n",
    "import json\n",
    "from collections import Counter\n",
    "import os\n",
    "import yaml\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['python-bot-config'] = \"/Users/ryanherren/python-bot-config.yaml\"\n",
    "# os.environ['python-bot-config'] = \"/Users/dunnt/python-bot-config.yaml\"\n",
    "# os.environ['python-bot-config'] = \"/Users/mariolgw/python-bot-config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    v_env = os.environ['python-bot-config']\n",
    "except:\n",
    "    print(\"Config file env variable is not set.\")\n",
    "    print(\"Set python-bot-config file\")\n",
    "    sys.exit(1)\n",
    "\n",
    "with open(v_env, \"r\") as yamlConfig:\n",
    "    cfg = yaml.safe_load(yamlConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = cfg.get(\"TwitterAPI\").get(\"consumer_key\")\n",
    "consumer_secret = cfg.get(\"TwitterAPI\").get(\"consumer_secret\")\n",
    "access_token = cfg.get(\"TwitterAPI\").get(\"access_token\")\n",
    "access_token_secret = cfg.get(\"TwitterAPI\").get(\"access_token_secret\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    " \n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Iterates through and writes individual objects to the file, doesn't work when parsing file later\n",
    "# f = open(\"tweets.json\", \"w\")\n",
    "# for tweet in tweepy.Cursor(api.home_timeline).items(10):\n",
    "#     json.dump(tweet._json, f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluates all Tweets on a the bot's home timeline\n",
    "# # Dumps raw json\n",
    "# api.home_timeline(items=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently limited to num_tweets Tweets\n",
    "def get_tweets_by_user(user):\n",
    "    tweets = api.user_timeline(user, items=12)\n",
    "    my_list_of_dicts = []\n",
    "    for each_json_tweet in tweets:\n",
    "        my_list_of_dicts.append(each_json_tweet._json)\n",
    "    filename = user + '.txt'\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(json.dumps(my_list_of_dicts, indent=4))\n",
    "    my_demo_list = []\n",
    "    with open(filename, encoding='utf-8') as json_file:  \n",
    "        all_data = json.load(json_file)\n",
    "        for each_dictionary in all_data:\n",
    "            tweet_id = each_dictionary['id']\n",
    "            text = each_dictionary['text']\n",
    "            favorite_count = each_dictionary['favorite_count']\n",
    "            retweet_count = each_dictionary['retweet_count']\n",
    "            created_at = each_dictionary['created_at']\n",
    "            my_demo_list.append({'tweet_id': str(tweet_id),\n",
    "                                 'text': str(text),\n",
    "                                 'favorite_count': int(favorite_count),\n",
    "                                 'retweet_count': int(retweet_count),\n",
    "                                 'created_at': created_at,\n",
    "                                })\n",
    "            #print(my_demo_list)\n",
    "            tweet_json = pd.DataFrame(my_demo_list, columns = \n",
    "                                      ['tweet_id', 'text', \n",
    "                                       'favorite_count', 'retweet_count', \n",
    "                                       'created_at'])\n",
    "    return tweet_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "ryan_tweets2 = get_tweets_by_user('nick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 5)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ryan_tweets2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1444867435840950281</td>\n",
       "      <td>@eviloars Come visit</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon Oct 04 03:30:15 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1444851476275236865</td>\n",
       "      <td>Colorado PSA: Aspens are at peak color in the ...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon Oct 04 02:26:50 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1444024870950473728</td>\n",
       "      <td>@cg Don‚Äôt worry. It was more a commentary on t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Fri Oct 01 19:42:12 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1443970787229065223</td>\n",
       "      <td>how october is going so far https://t.co/cumD2...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Fri Oct 01 16:07:18 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1433674940864024580</td>\n",
       "      <td>RT @_tomcashman: Somehow we ended up here http...</td>\n",
       "      <td>0</td>\n",
       "      <td>60802</td>\n",
       "      <td>Fri Sep 03 06:15:16 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1390007073232982018</td>\n",
       "      <td>RT @1AbbyRoad: ‚ÄúNo worries if not!‚Äù https://t....</td>\n",
       "      <td>0</td>\n",
       "      <td>27791</td>\n",
       "      <td>Wed May 05 18:14:45 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1359618955913007104</td>\n",
       "      <td>RT @bimadew: this is so gentle https://t.co/Cb...</td>\n",
       "      <td>0</td>\n",
       "      <td>1819</td>\n",
       "      <td>Wed Feb 10 21:43:14 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1334552503203950596</td>\n",
       "      <td>RT @reganbich: hi twitter i never do stuff lik...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>Thu Dec 03 17:38:06 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1325125756633018368</td>\n",
       "      <td>RT @VanJones68: Today is a good day. \\nIt‚Äôs ea...</td>\n",
       "      <td>0</td>\n",
       "      <td>72633</td>\n",
       "      <td>Sat Nov 07 17:19:34 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1325114551176552451</td>\n",
       "      <td>I‚Äôve been waiting four years for this moment</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Sat Nov 07 16:35:03 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1286054825008955392</td>\n",
       "      <td>RT @JoshuaPotash: Jesus feds just came directl...</td>\n",
       "      <td>0</td>\n",
       "      <td>18553</td>\n",
       "      <td>Wed Jul 22 21:45:38 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1285414289721880576</td>\n",
       "      <td>RT @JuliusGoat: This is open fascism.\\n\\nNow t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1485</td>\n",
       "      <td>Tue Jul 21 03:20:23 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1284172919862509569</td>\n",
       "      <td>RT @OPB: Federal officers have been using unma...</td>\n",
       "      <td>0</td>\n",
       "      <td>9385</td>\n",
       "      <td>Fri Jul 17 17:07:37 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1283014528125603846</td>\n",
       "      <td>RT @Lollardfish: If we had just canceled every...</td>\n",
       "      <td>0</td>\n",
       "      <td>10542</td>\n",
       "      <td>Tue Jul 14 12:24:35 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1280946758156267528</td>\n",
       "      <td>RT @KyleKulinski: Japan has less than 1,000 co...</td>\n",
       "      <td>0</td>\n",
       "      <td>130514</td>\n",
       "      <td>Wed Jul 08 19:28:00 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1271512083599785984</td>\n",
       "      <td>RT @kylekotajarvi: A masterpiece was created i...</td>\n",
       "      <td>0</td>\n",
       "      <td>60614</td>\n",
       "      <td>Fri Jun 12 18:37:58 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1252105260396511232</td>\n",
       "      <td>PSA: this website has a great settlers of cata...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon Apr 20 05:22:11 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1239276720802238464</td>\n",
       "      <td>RT @JasonYanowitz: If you'e still hanging with...</td>\n",
       "      <td>0</td>\n",
       "      <td>173635</td>\n",
       "      <td>Sun Mar 15 19:46:09 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1234550859490418688</td>\n",
       "      <td>@XXL @therealelp That‚Äôs not your mouth, that‚Äôs...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon Mar 02 18:47:16 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1234231553334464512</td>\n",
       "      <td>RT @JeremyKonyndyk: Now seems highly likely th...</td>\n",
       "      <td>0</td>\n",
       "      <td>5498</td>\n",
       "      <td>Sun Mar 01 21:38:27 +0000 2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet_id                                               text  \\\n",
       "0   1444867435840950281                               @eviloars Come visit   \n",
       "1   1444851476275236865  Colorado PSA: Aspens are at peak color in the ...   \n",
       "2   1444024870950473728  @cg Don‚Äôt worry. It was more a commentary on t...   \n",
       "3   1443970787229065223  how october is going so far https://t.co/cumD2...   \n",
       "4   1433674940864024580  RT @_tomcashman: Somehow we ended up here http...   \n",
       "5   1390007073232982018  RT @1AbbyRoad: ‚ÄúNo worries if not!‚Äù https://t....   \n",
       "6   1359618955913007104  RT @bimadew: this is so gentle https://t.co/Cb...   \n",
       "7   1334552503203950596  RT @reganbich: hi twitter i never do stuff lik...   \n",
       "8   1325125756633018368  RT @VanJones68: Today is a good day. \\nIt‚Äôs ea...   \n",
       "9   1325114551176552451       I‚Äôve been waiting four years for this moment   \n",
       "10  1286054825008955392  RT @JoshuaPotash: Jesus feds just came directl...   \n",
       "11  1285414289721880576  RT @JuliusGoat: This is open fascism.\\n\\nNow t...   \n",
       "12  1284172919862509569  RT @OPB: Federal officers have been using unma...   \n",
       "13  1283014528125603846  RT @Lollardfish: If we had just canceled every...   \n",
       "14  1280946758156267528  RT @KyleKulinski: Japan has less than 1,000 co...   \n",
       "15  1271512083599785984  RT @kylekotajarvi: A masterpiece was created i...   \n",
       "16  1252105260396511232  PSA: this website has a great settlers of cata...   \n",
       "17  1239276720802238464  RT @JasonYanowitz: If you'e still hanging with...   \n",
       "18  1234550859490418688  @XXL @therealelp That‚Äôs not your mouth, that‚Äôs...   \n",
       "19  1234231553334464512  RT @JeremyKonyndyk: Now seems highly likely th...   \n",
       "\n",
       "    favorite_count  retweet_count                      created_at  \n",
       "0                1              0  Mon Oct 04 03:30:15 +0000 2021  \n",
       "1               11              1  Mon Oct 04 02:26:50 +0000 2021  \n",
       "2                1              0  Fri Oct 01 19:42:12 +0000 2021  \n",
       "3                9              1  Fri Oct 01 16:07:18 +0000 2021  \n",
       "4                0          60802  Fri Sep 03 06:15:16 +0000 2021  \n",
       "5                0          27791  Wed May 05 18:14:45 +0000 2021  \n",
       "6                0           1819  Wed Feb 10 21:43:14 +0000 2021  \n",
       "7                0           2023  Thu Dec 03 17:38:06 +0000 2020  \n",
       "8                0          72633  Sat Nov 07 17:19:34 +0000 2020  \n",
       "9               10              2  Sat Nov 07 16:35:03 +0000 2020  \n",
       "10               0          18553  Wed Jul 22 21:45:38 +0000 2020  \n",
       "11               0           1485  Tue Jul 21 03:20:23 +0000 2020  \n",
       "12               0           9385  Fri Jul 17 17:07:37 +0000 2020  \n",
       "13               0          10542  Tue Jul 14 12:24:35 +0000 2020  \n",
       "14               0         130514  Wed Jul 08 19:28:00 +0000 2020  \n",
       "15               0          60614  Fri Jun 12 18:37:58 +0000 2020  \n",
       "16               6              0  Mon Apr 20 05:22:11 +0000 2020  \n",
       "17               0         173635  Sun Mar 15 19:46:09 +0000 2020  \n",
       "18               1              0  Mon Mar 02 18:47:16 +0000 2020  \n",
       "19               0           5498  Sun Mar 01 21:38:27 +0000 2020  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ryan_tweets2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is the basis of how tokenizing the Tweet will work. Using regex statments, it accounts for emojis, \n",
    "# hashtags, mentions, and more.\n",
    "import re\n",
    " \n",
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    " \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "    \n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    " \n",
    "def tokenize(s):\n",
    "    return tokens_re.findall(s)\n",
    " \n",
    "def preprocess(s, lowercase=False):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT',\n",
       " '@CycloneMBB',\n",
       " ':',\n",
       " 'Lights',\n",
       " 'always',\n",
       " 'shine',\n",
       " 'brighter',\n",
       " 'at',\n",
       " 'Hilton',\n",
       " 'Coliseum',\n",
       " '!',\n",
       " 'ü§©',\n",
       " '#C5C',\n",
       " '|',\n",
       " '#Cyclones',\n",
       " 'üå™',\n",
       " 'https://t.co/5Lt0Cd9j6I']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(ryan_tweets.loc[8]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT',\n",
       " '@CycloneMBB',\n",
       " ':',\n",
       " 'Lights',\n",
       " 'always',\n",
       " 'shine',\n",
       " 'brighter',\n",
       " 'at',\n",
       " 'Hilton',\n",
       " 'Coliseum',\n",
       " '!',\n",
       " 'ü§©',\n",
       " '#C5C',\n",
       " '|',\n",
       " '#Cyclones',\n",
       " 'üå™',\n",
       " 'https://t.co/5Lt0Cd9j6I']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(ryan_tweets.loc[8]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "punctuation = list(string.punctuation)\n",
    "stop = stopwords.words('english') + punctuation + ['rt', 'via', '‚Äô', 'RT', 'Ô∏è']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('üå™', 17), ('#Cyclones', 6), ('@CycloneWBB', 4), ('üèÄ', 4), ('üé•', 3)]\n"
     ]
    }
   ],
   "source": [
    "count_all = Counter()\n",
    "for tweet in ryan_tweets['text']:\n",
    "    #terms_all = [term for term in preprocess(tweet)]\n",
    "    terms_stop = [term for term in preprocess(tweet) if term not in stop]\n",
    "    count_all.update(terms_stop)\n",
    "    #print(tweet + \"\\n\")\n",
    "print(count_all.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
