{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object here is to train a machine learning model on a database of Tweets and use that model to predict sentiment of Tweets from a user, a hashtag, or any random variety of Tweets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**@author Ryan Herren**\n",
    "\n",
    "**@author Tanner Dunn**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize environment, install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ryanherren/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator \n",
    "import json\n",
    "from collections import Counter\n",
    "import os\n",
    "import yaml\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['python-bot-config'] = \"/Users/ryanherren/python-bot-config.yaml\"\n",
    "# os.environ['python-bot-config'] = \"/Users/dunnt/python-bot-config.yaml\"\n",
    "# os.environ['python-bot-config'] = \"/Users/mariolgw/python-bot-config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    v_env = os.environ['python-bot-config']\n",
    "except:\n",
    "    print(\"Config file env variable is not set.\")\n",
    "    print(\"Set python-bot-config file\")\n",
    "    sys.exit(1)\n",
    "\n",
    "with open(v_env, \"r\") as yamlConfig:\n",
    "    cfg = yaml.safe_load(yamlConfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Opinion Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading negative words list:\n",
    "with open('negative-words.txt', 'r', encoding = \"ISO-8859-1\") as t:\n",
    "    neg = t.readlines()\n",
    "    neg_words = []\n",
    "    for i in neg:\n",
    "        neg_words.append(i.strip())\n",
    "    del neg_words[0 : 31]\n",
    "    \n",
    "\n",
    "# Reading positive words list:\n",
    "with open('positive-words.txt', 'r', encoding = \"ISO-8859-1\") as t:\n",
    "    pos = t.readlines()\n",
    "    pos_words = []\n",
    "    for i in pos:\n",
    "        pos_words.append(i.strip())\n",
    "    del pos_words[0 : 30]\n",
    "    \n",
    "positive_emojis = ['ğŸ˜‚','ğŸ”¥','ğŸ˜','ğŸ¤˜','ğŸ¤©','ğŸ‘','ğŸ’¯','ğŸ˜','âœ…','ğŸ‘','ğŸ˜€','ğŸ',\n",
    "                   'â¤ï¸','â™¥ï¸','ğŸ˜˜','ğŸ˜Š','ğŸ˜„','ğŸ˜ƒ','ğŸ˜†','ğŸ˜‹','ğŸ¤ª','ğŸ˜œ','ğŸ˜›','ğŸ¤‘']\n",
    "negative_emojis = ['ğŸ¥´','ğŸ¤¢','ğŸ¤®','ğŸ˜§','ğŸ˜‘','ğŸ˜°','ğŸ¤¬','ğŸ˜¡','ğŸ˜­','ğŸ˜¢','ğŸ˜©','ğŸ™',\n",
    "                   'â˜¹ï¸','ğŸ˜£','ğŸ˜–','ğŸ˜«','ğŸ˜Ÿ','ğŸ˜','ğŸ˜”','ğŸ˜’','ğŸ‘¿','ğŸ¤•','ğŸ¤’','ğŸ˜·']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to count sentiment words in Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count negative words in tweet:\n",
    "def count_negative(tweet):\n",
    "    neg_word_count = 0\n",
    "    for word in tweet:\n",
    "        if word in neg_words:\n",
    "            neg_word_count = neg_word_count + 1\n",
    "            # mg['neg_word_count'] = mg['text'].apply(lambda x: neg_word_count(x), axis = 1, result_type = 'expand')\n",
    "    return neg_word_count\n",
    "   \n",
    "# Function to count positive words in tweet:\n",
    "def count_positive(tweet):\n",
    "    pos_word_count = 0\n",
    "    for word in tweet:\n",
    "        #print(word)\n",
    "        if word in pos_words:\n",
    "            pos_word_count = pos_word_count + 1\n",
    "            # mg['neg_word_count'] = mg['text'].apply(lambda x: neg_word_count(x), axis = 1, result_type = 'expand')\n",
    "    return pos_word_count\n",
    "   \n",
    "def count_mentions(tweet):\n",
    "    num_mentions = 0\n",
    "    for word in tweet:\n",
    "        if word.startswith('@'):\n",
    "            num_mentions = num_mentions + 1\n",
    "    return num_mentions\n",
    "\n",
    "def count_hashtags(tweet):\n",
    "    num_hashtags = 0\n",
    "    for word in tweet:\n",
    "        if word.startswith('#'):\n",
    "            num_hashtags = num_hashtags + 1\n",
    "    return num_hashtags\n",
    "\n",
    "def count_positive_emojis(tweet):\n",
    "    pos_emoji_count = 0\n",
    "    for word in tweet:\n",
    "        #print(word)\n",
    "        if word in positive_emojis:\n",
    "            pos_emoji_count = pos_emoji_count + 1\n",
    "            # mg['neg_word_count'] = mg['text'].apply(lambda x: neg_word_count(x), axis = 1, result_type = 'expand')\n",
    "    return pos_emoji_count\n",
    "\n",
    "def count_negative_emojis(tweet):\n",
    "    neg_emoji_count = 0\n",
    "    for word in tweet:\n",
    "        #print(word)\n",
    "        if word in negative_emojis:\n",
    "            neg_emoji_count = neg_emoji_count + 1\n",
    "            # mg['neg_word_count'] = mg['text'].apply(lambda x: neg_word_count(x), axis = 1, result_type = 'expand')\n",
    "    return neg_emoji_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing functions to break tweets into words, emojis, mentions, and hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is the basis of how tokenizing the Tweet will work. Using regex statments, it accounts for emojis, \n",
    "# hashtags, mentions, and more.\n",
    "import re\n",
    " \n",
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    " \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "    \n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    " \n",
    "def tokenize(s):\n",
    "    return tokens_re.findall(s)\n",
    " \n",
    "def preprocess(s, lowercase=False):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Twitter API Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = cfg.get(\"TwitterAPI\").get(\"consumer_key\")\n",
    "consumer_secret = cfg.get(\"TwitterAPI\").get(\"consumer_secret\")\n",
    "access_token = cfg.get(\"TwitterAPI\").get(\"access_token\")\n",
    "access_token_secret = cfg.get(\"TwitterAPI\").get(\"access_token_secret\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    " \n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Tweets by User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently limited to num_tweets Tweets\n",
    "column_names = ['tweet_id', 'text','favorite_count','retweet_count','created_at']\n",
    "def get_tweets_by_user(user, tweets):\n",
    "    tweet_json = pd.DataFrame(columns=column_names)\n",
    "    for i in range(math.ceil(tweets/20)):\n",
    "        tweets = api.user_timeline(user, page=i)\n",
    "#         print(str(i) + \"WABBADABBADO\\n\")\n",
    "#         print(tweets)\n",
    "        my_list_of_dicts = []\n",
    "        for each_json_tweet in tweets:\n",
    "            my_list_of_dicts.append(each_json_tweet._json)\n",
    "        filename = user + '.txt'\n",
    "        if os.path.exists(filename):\n",
    "            os.remove(filename)\n",
    "        with open(filename, 'w') as file:\n",
    "            file.write(json.dumps(my_list_of_dicts, indent=4))\n",
    "        my_demo_list = []\n",
    "        with open(filename, encoding='utf-8') as json_file:  \n",
    "            all_data = json.load(json_file)\n",
    "            for each_dictionary in all_data:\n",
    "                tweet_id = each_dictionary['id']\n",
    "                text = each_dictionary['text']\n",
    "                favorite_count = each_dictionary['favorite_count']\n",
    "                retweet_count = each_dictionary['retweet_count']\n",
    "                created_at = each_dictionary['created_at']\n",
    "                my_demo_list.append({'tweet_id': str(tweet_id),\n",
    "                                     'text': str(text),\n",
    "                                     'favorite_count': int(favorite_count),\n",
    "                                     'retweet_count': int(retweet_count),\n",
    "                                     'created_at': created_at,\n",
    "                                    })\n",
    "                #print(my_demo_list)\n",
    "                temp_json = pd.DataFrame(my_demo_list, columns = \n",
    "                                          ['tweet_id', 'text', \n",
    "                                           'favorite_count', 'retweet_count', \n",
    "                                           'created_at'])\n",
    "#             print(\"\\n \\n \" + str(temp_json.shape) + str(type(temp_json)) + \"\\n\\n\")\n",
    "        tweet_json = tweet_json.append(temp_json, ignore_index=True)\n",
    "#         print(\"\\n \\n \" + str(tweet_json.shape) + str(type(tweet_json)) + \"\\n\\n\")\n",
    "    tweet_json = tweet_json.drop_duplicates()    \n",
    "    return tweet_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Tweets by Hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_tweets = get_tweets_by_user('DS301Bot', 109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1467259093375143940</td>\n",
       "      <td>ğŸ¥´ğŸ¤¢ğŸ¤®ğŸ˜§ğŸ˜‘ğŸ˜°ğŸ¤¬ğŸ˜¡ğŸ˜­ğŸ˜¢ğŸ˜©ğŸ™â˜¹ï¸ğŸ˜£ğŸ˜–ğŸ˜«ğŸ˜ŸğŸ˜ğŸ˜”ğŸ˜’ğŸ‘¿ğŸ¤•ğŸ¤’ğŸ˜·</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sat Dec 04 22:26:42 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1467256679561633792</td>\n",
       "      <td>ğŸ˜‚ğŸ”¥ğŸ˜ğŸ¤˜ğŸ¼ğŸ¤©ğŸ‘ğŸ¼ğŸ’¯ğŸ˜âœ…ğŸ‘ğŸ¼ğŸ˜€ğŸâ¤ï¸â™¥ï¸ğŸ˜˜ğŸ˜ŠğŸ˜„ğŸ˜ƒğŸ˜†ğŸ˜‹ğŸ¤ªğŸ˜œğŸ˜›ğŸ¤‘</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sat Dec 04 22:17:07 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463255944565977092</td>\n",
       "      <td>Hello friends. I am a friendly bot.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Tue Nov 23 21:19:37 +0000 2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                 text favorite_count  \\\n",
       "0  1467259093375143940            ğŸ¥´ğŸ¤¢ğŸ¤®ğŸ˜§ğŸ˜‘ğŸ˜°ğŸ¤¬ğŸ˜¡ğŸ˜­ğŸ˜¢ğŸ˜©ğŸ™â˜¹ï¸ğŸ˜£ğŸ˜–ğŸ˜«ğŸ˜ŸğŸ˜ğŸ˜”ğŸ˜’ğŸ‘¿ğŸ¤•ğŸ¤’ğŸ˜·              0   \n",
       "1  1467256679561633792        ğŸ˜‚ğŸ”¥ğŸ˜ğŸ¤˜ğŸ¼ğŸ¤©ğŸ‘ğŸ¼ğŸ’¯ğŸ˜âœ…ğŸ‘ğŸ¼ğŸ˜€ğŸâ¤ï¸â™¥ï¸ğŸ˜˜ğŸ˜ŠğŸ˜„ğŸ˜ƒğŸ˜†ğŸ˜‹ğŸ¤ªğŸ˜œğŸ˜›ğŸ¤‘              0   \n",
       "2  1463255944565977092  Hello friends. I am a friendly bot.              1   \n",
       "\n",
       "  retweet_count                      created_at  \n",
       "0             0  Sat Dec 04 22:26:42 +0000 2021  \n",
       "1             0  Sat Dec 04 22:17:07 +0000 2021  \n",
       "2             0  Tue Nov 23 21:19:37 +0000 2021  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tweets['tokenized'] = user_tweets['text'].apply(lambda x: tokenize(x))\n",
    "user_tweets['pos_words'] = user_tweets['tokenized'].apply(lambda x: count_positive(x))\n",
    "user_tweets['neg_words'] = user_tweets['tokenized'].apply(lambda x: count_negative(x))\n",
    "user_tweets['num_mentions'] = user_tweets['tokenized'].apply(lambda x: count_mentions(x))\n",
    "user_tweets['num_hashtags'] = user_tweets['tokenized'].apply(lambda x: count_hashtags(x))\n",
    "user_tweets['num_positive_emojis'] = user_tweets['tokenized'].apply(lambda x: count_positive_emojis(x))\n",
    "user_tweets['num_negative_emojis'] = user_tweets['tokenized'].apply(lambda x: count_negative_emojis(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>pos_words</th>\n",
       "      <th>neg_words</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_positive_emojis</th>\n",
       "      <th>num_negative_emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1467259093375143940</td>\n",
       "      <td>ğŸ¥´ğŸ¤¢ğŸ¤®ğŸ˜§ğŸ˜‘ğŸ˜°ğŸ¤¬ğŸ˜¡ğŸ˜­ğŸ˜¢ğŸ˜©ğŸ™â˜¹ï¸ğŸ˜£ğŸ˜–ğŸ˜«ğŸ˜ŸğŸ˜ğŸ˜”ğŸ˜’ğŸ‘¿ğŸ¤•ğŸ¤’ğŸ˜·</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sat Dec 04 22:26:42 +0000 2021</td>\n",
       "      <td>[ğŸ¥´, ğŸ¤¢, ğŸ¤®, ğŸ˜§, ğŸ˜‘, ğŸ˜°, ğŸ¤¬, ğŸ˜¡, ğŸ˜­, ğŸ˜¢, ğŸ˜©, ğŸ™, â˜¹, ï¸, ğŸ˜£, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1467256679561633792</td>\n",
       "      <td>ğŸ˜‚ğŸ”¥ğŸ˜ğŸ¤˜ğŸ¼ğŸ¤©ğŸ‘ğŸ¼ğŸ’¯ğŸ˜âœ…ğŸ‘ğŸ¼ğŸ˜€ğŸâ¤ï¸â™¥ï¸ğŸ˜˜ğŸ˜ŠğŸ˜„ğŸ˜ƒğŸ˜†ğŸ˜‹ğŸ¤ªğŸ˜œğŸ˜›ğŸ¤‘</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sat Dec 04 22:17:07 +0000 2021</td>\n",
       "      <td>[ğŸ˜‚, ğŸ”¥, ğŸ˜, ğŸ¤˜, ğŸ¼, ğŸ¤©, ğŸ‘, ğŸ¼, ğŸ’¯, ğŸ˜, âœ…, ğŸ‘, ğŸ¼, ğŸ˜€, ğŸ, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463255944565977092</td>\n",
       "      <td>Hello friends. I am a friendly bot.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Tue Nov 23 21:19:37 +0000 2021</td>\n",
       "      <td>[Hello, friends, ., I, am, a, friendly, bot, .]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                 text favorite_count  \\\n",
       "0  1467259093375143940            ğŸ¥´ğŸ¤¢ğŸ¤®ğŸ˜§ğŸ˜‘ğŸ˜°ğŸ¤¬ğŸ˜¡ğŸ˜­ğŸ˜¢ğŸ˜©ğŸ™â˜¹ï¸ğŸ˜£ğŸ˜–ğŸ˜«ğŸ˜ŸğŸ˜ğŸ˜”ğŸ˜’ğŸ‘¿ğŸ¤•ğŸ¤’ğŸ˜·              0   \n",
       "1  1467256679561633792        ğŸ˜‚ğŸ”¥ğŸ˜ğŸ¤˜ğŸ¼ğŸ¤©ğŸ‘ğŸ¼ğŸ’¯ğŸ˜âœ…ğŸ‘ğŸ¼ğŸ˜€ğŸâ¤ï¸â™¥ï¸ğŸ˜˜ğŸ˜ŠğŸ˜„ğŸ˜ƒğŸ˜†ğŸ˜‹ğŸ¤ªğŸ˜œğŸ˜›ğŸ¤‘              0   \n",
       "2  1463255944565977092  Hello friends. I am a friendly bot.              1   \n",
       "\n",
       "  retweet_count                      created_at  \\\n",
       "0             0  Sat Dec 04 22:26:42 +0000 2021   \n",
       "1             0  Sat Dec 04 22:17:07 +0000 2021   \n",
       "2             0  Tue Nov 23 21:19:37 +0000 2021   \n",
       "\n",
       "                                           tokenized  pos_words  neg_words  \\\n",
       "0  [ğŸ¥´, ğŸ¤¢, ğŸ¤®, ğŸ˜§, ğŸ˜‘, ğŸ˜°, ğŸ¤¬, ğŸ˜¡, ğŸ˜­, ğŸ˜¢, ğŸ˜©, ğŸ™, â˜¹, ï¸, ğŸ˜£, ...          0          0   \n",
       "1  [ğŸ˜‚, ğŸ”¥, ğŸ˜, ğŸ¤˜, ğŸ¼, ğŸ¤©, ğŸ‘, ğŸ¼, ğŸ’¯, ğŸ˜, âœ…, ğŸ‘, ğŸ¼, ğŸ˜€, ğŸ, ...          0          0   \n",
       "2    [Hello, friends, ., I, am, a, friendly, bot, .]          1          0   \n",
       "\n",
       "   num_mentions  num_hashtags  num_positive_emojis  num_negative_emojis  \n",
       "0             0             0                    0                   23  \n",
       "1             0             0                   22                    0  \n",
       "2             0             0                    0                    0  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# punctuation = list(string.punctuation)\n",
    "# stop = stopwords.words('english') + punctuation + ['rt', 'via', 'â€™', 'RT', 'ï¸', 'â€¦']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOU ALL NEED TO TOUCH GRASS\n",
      "\n",
      "@ElamarDaGreat Love you man best of luck!\n",
      "\n",
      "@tomh1138 @jakebrend32 There is no friction between Campbell and Pollard and Matt Campbell will be in Ames, Iowa coâ€¦ https://t.co/CupKqzCsH9\n",
      "\n",
      "RT @WillBlackmon: Brian Kelly at first interview after practice at LSU https://t.co/J4HneZqUVy\n",
      "\n",
      "@ImDerBatman @GilletteLD Boyyyyyyy\n",
      "\n",
      "@GilletteLD @ImDerBatman Bill Oâ€™Brien\n",
      "\n",
      "@drakectoll A Baylor fan that can afford losing a hamstring?\n",
      "\n",
      "FIFTEEN MILLION DOLLARS\n",
      "\n",
      "@dennisdoddcbs @PeteThamel Itâ€™s Dennis Doddâ€™s time to lick my nuts\n",
      "\n",
      "Do you think Steele Jantz knows about all this?\n",
      "\n",
      "Congrats bro @itshanklol!\n",
      "\n",
      "They said your hamstrings werenâ€™t good enough, but keep proven the haters wrongğŸ˜¤âœŠ https://t.co/A0Z8vPlrDr\n",
      "\n",
      "RT @G_Bombastic: YOOOO ğŸ˜­ğŸ˜­ https://t.co/Gu8ogF4nnk\n",
      "\n",
      "Yup.\n",
      "\n",
      "Bob Stoops and Lincoln Riley situation, but Brian decided to get that bread before retiring all the way https://t.co/X0vVeIPQ4o\n",
      "\n",
      "@AidenWyatt01 AIDEN\n",
      "\n",
      "@tKCyclone Brother what?\n",
      "\n",
      "@steveryancarter Itâ€™s gotta be my nuts to your face\n",
      "\n",
      "@isutwirlybird I donâ€™t know shit\n",
      "\n",
      "My nuts have never been safer https://t.co/ghaVfkqNlb\n",
      "\n",
      "RT @EvanHebert: what do yall think Brian Kelly and Kim Mulkey are going to talk about\n",
      "\n",
      "RELAX\n",
      "\n",
      "How silly I was to doubt the Otz hire\n",
      "\n",
      "Jamie Pollard is talking about me on the radio\n",
      "\n",
      "Being realistic heâ€™s probably 6th on their list at best\n",
      "\n",
      "JAMIE BROUGHT UP THE CALIFORNIA TAX RATE LMFAO\n",
      "\n",
      "â€œTry wearin black at USCâ€\n",
      "\n",
      "Hell yeah Jamie\n",
      "\n",
      "Jamie is talking like a man that knows something good\n",
      "\n",
      "Jamie just called himself a unicorn and unicorns are magical which means he will use his magic to keep him stop worrying you clowns\n",
      "\n",
      "Itâ€™s under by the way but hell yeah Brian cash that check https://t.co/IqQlhCUG9x\n",
      "\n",
      "Itâ€™s under by the way\n",
      "\n",
      "Over under 3.5 years until Kelly is fired at LSU\n",
      "\n",
      "@palmer4Cy ITS COMING OKAY\n",
      "\n",
      "And if he doesnâ€™t Bob Stoops will fill the role until heâ€™s ready https://t.co/EWb6SBT3ki\n",
      "\n",
      "Marcus Freeman will be hired the second Kelly signs the papers with LSU https://t.co/jXBO6ZWGvL\n",
      "\n",
      "Yâ€™all relax he ainâ€™t goin to Notre Dame\n",
      "\n",
      "@clonesjer Gaines and Essex will make immediate impacts. Noel is gonna be a stud. If Hutch is back theyâ€™re gonna cause some problems\n",
      "\n",
      "Have I ever mentioned a love this man https://t.co/d7q2W2vS3i\n",
      "\n",
      "This hurts but our wide receiver room is loaded next year. Especially if Hutch stays around https://t.co/oIhSNzkznM\n",
      "\n",
      "Build Lincoln Riley a statue in Ames https://t.co/DyW7IMm25h\n",
      "\n",
      "Theyâ€™re just gonna hire Stoops arenâ€™t they\n",
      "\n",
      "Build the statue https://t.co/6NqzR6mBhz\n",
      "\n",
      "@NotMattCampbell Soon\n",
      "\n",
      "Also proof these arenâ€™t the greatest stats to judge a team by\n",
      "\n",
      "Pain https://t.co/67qvmKm5Id\n",
      "\n",
      "RT @HyVee: Happy birthday, @ISUMattCampbell! ğŸ¥³ ğŸ‰ https://t.co/EQeqmm3fwK\n",
      "\n",
      "Oh man OU is hiring the guy that got his defense from Iowa State Iâ€™m terrified #bums\n",
      "\n",
      "Canâ€™t wait for Tom Manning to put Brent Venables through 60 minutes of hell\n",
      "\n",
      "@tinyhippo2 OU presser announcinG BRENT Venables\n",
      "\n",
      "https://t.co/LnZ9BVeYY3\n",
      "\n",
      "Final domino falling at 3:00\n",
      "\n",
      "@blinkinriley Total defense for Venebals?\n",
      "\n",
      "Canâ€™t believe we have two coaches that hate winning https://t.co/s8XmWHY4Ua\n",
      "\n",
      "@counselorfrog Iâ€™m just in a silly goofy mood\n",
      "\n",
      "Max Duggan https://t.co/xMa7pofVQM\n",
      "\n",
      "@tcalgaard My laundry is done\n",
      "\n",
      "https://t.co/blBCA3TbId\n",
      "\n",
      "@RJHINDM @EthanJEarlywine I knew you had good genes\n",
      "\n",
      "This is JFK JR. Right?\n",
      "\n",
      "@OurDailyBears @itshanklol I giggled\n",
      "\n",
      "@OurDailyBears @itshanklol Omg\n",
      "\n",
      "https://t.co/79AqEdOapP https://t.co/g43hG3gwRp\n",
      "\n",
      "OU Brass watching the program blow up after deciding to move to the SEC https://t.co/CxqvO7eOja\n",
      "\n",
      "@BigGameBoomer @OU_Football @CoachBobStoops The school gutted themselves when they decided to go to the SEC\n",
      "\n",
      "RT @SpencerRattler: https://t.co/KGMIovUSis\n",
      "\n",
      "@the_joe_goodman @mattisbear No\n",
      "\n",
      "@the_joe_goodman Iâ€™m horrified\n",
      "\n",
      "@the_joe_goodman Who the fuck is Scott Drew\n",
      "\n",
      "@ajkorver71 They havenâ€™t played anyone with a pulse. Win tonight and theyâ€™ll be in next week\n",
      "\n",
      "@ImDerBatman Real men cry every time\n",
      "\n",
      "@JaredStansbury @ToddBrommelkamp What in tarnation\n",
      "\n",
      "@ToddBrommelkamp WELL THIS IS LIKE COCAINE AND VOTING FOR KANYE\n",
      "\n",
      "@cfchangs9 @MatthiasWRNL Yeah I did\n",
      "\n",
      "Talk to your kids about the top 10 matchup between the Iowa State Cyclones and Baylor Bears in Hilton Coliseum on New Years Day\n",
      "\n",
      "Oh itâ€™s the team an undefeated #19 just throttled by a bajillion points https://t.co/DfH13rL793\n",
      "\n",
      "Excuse me WHO is ranked #18????\n",
      "\n",
      "YOU BETTER HAVE TOLD YOUR CHILDREN https://t.co/kZH5QQNH81\n",
      "\n",
      "RT @tylerljohnson67: I'd love to read the txt group chat between the hateful 8 AD's this weekend.\n",
      "\n",
      "Evergreen https://t.co/ff7Js3TXTb\n",
      "\n",
      "@MNelson_ISU @BuschBeer And?\n",
      "\n",
      "Happy Birthday Indeed https://t.co/wNsyTSv5gW\n",
      "\n",
      "RT @CycloneFB: Happy Birthday, Coach Campbell!\n",
      "\n",
      "ğŸŒªï¸ğŸš¨ğŸŒªï¸ https://t.co/60dNp3rsb2\n",
      "\n",
      "Ope https://t.co/8yWIMKjH3W\n",
      "\n",
      "@the_joe_goodman @RedDirtSport Me thinking about him every time Iâ€™m about to fire off an OU hate tweet https://t.co/zaWZuk1ow8\n",
      "\n",
      "RT @j_swishy_35: @CycloneLarry69 One last chance to talk to your children before the poll comes out this afternoon https://t.co/cEvojyh5SW\n",
      "\n",
      "@TEEnsign Hey they helped!\n",
      "\n",
      "@itshanklol I donâ€™t see any way Michigan wins the B12 title IMO\n",
      "\n",
      "Leaving a conference youâ€™ve been in for 100 years hasnâ€™t worked out this poorly for a school since the last time soâ€¦ https://t.co/ti26PTP4F3\n",
      "\n",
      "@gmackey32 I want hogs in the trenches. He will give me hogs in the trenches\n",
      "\n",
      "RT @gmackey32: If Lincoln Riley doesnâ€™t take Bill Bedenbaugh with him, Campbell HAS to make that phone call and give him whatever he wantsâ€¦\n",
      "\n",
      "If only history gave us examples they couldâ€™ve learned from https://t.co/LDQztPqEM2\n",
      "\n",
      "https://t.co/RumbiirVOc https://t.co/OeRv5QUF3q\n",
      "\n",
      "Oh so theyâ€™re screwed screwed https://t.co/TqX5bINbcb\n",
      "\n",
      "https://t.co/mVOts9t0yJ https://t.co/1mO2qplSHA\n",
      "\n",
      "Good morning https://t.co/RSroACkU2u\n",
      "\n",
      "RT @Eddie_Rado: People are taking this well in Norman. Credit anonymous source via Instagram DMs. https://t.co/Pm2owPPbWU\n",
      "\n",
      "Bill Oâ€™Brien https://t.co/nKSmD0oDJp\n",
      "\n",
      "Goodnight my beautiful friends\n",
      "\n",
      "Just remembered OU has to play at Nebraska next season\n",
      "\n",
      "@ImDerBatman #neverforget\n",
      "\n",
      "@SpurHorn Iâ€™m skeptical\n",
      "\n",
      "@troybking When they fired Mack Brown\n",
      "\n",
      "[('I', 13), ('OU', 5), ('man', 4), ('Campbell', 4), ('Brian', 4), ('Kelly', 4), ('@ImDerBatman', 4), ('It', 4), ('time', 4), ('@itshanklol', 4)]\n"
     ]
    }
   ],
   "source": [
    "# count_all = Counter()\n",
    "# for tweet in user_tweets['text']:\n",
    "#     terms_all = [term for term in preprocess(tweet)]\n",
    "#     terms_stop = [term for term in preprocess(tweet) if term not in stop]\n",
    "#     count_all.update(terms_stop)\n",
    "#     print(tweet + \"\\n\")\n",
    "# print(count_all.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
