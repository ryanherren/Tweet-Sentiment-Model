{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object here is to train a machine learning model on a database of Tweets and use that model to predict sentiment of Tweets from a user, a hashtag, or any random variety of Tweets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**@author Ryan Herren**\n",
    "\n",
    "**@author Tanner Dunn**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following link is a good informational guide on how to roughly implement a model like we are aiming for. https://www.analyticsvidhya.com/blog/2021/06/twitter-sentiment-analysis-a-nlp-use-case-for-beginners/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize environment, install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ryanherren/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator \n",
    "import json\n",
    "from collections import Counter\n",
    "import os\n",
    "import yaml\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['python-bot-config'] = \"/Users/ryanherren/python-bot-config.yaml\"\n",
    "# os.environ['python-bot-config'] = \"/Users/dunnt/python-bot-config.yaml\"\n",
    "# os.environ['python-bot-config'] = \"/Users/mariolgw/python-bot-config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    v_env = os.environ['python-bot-config']\n",
    "except:\n",
    "    print(\"Config file env variable is not set.\")\n",
    "    print(\"Set python-bot-config file\")\n",
    "    sys.exit(1)\n",
    "\n",
    "with open(v_env, \"r\") as yamlConfig:\n",
    "    cfg = yaml.safe_load(yamlConfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Opinion Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading negative words list:\n",
    "with open('negative-words.txt', 'r', encoding = \"ISO-8859-1\") as t:\n",
    "    neg = t.readlines()\n",
    "    neg_words = []\n",
    "    for i in neg:\n",
    "        neg_words.append(i.strip())\n",
    "    del neg_words[0 : 31]\n",
    "    \n",
    "\n",
    "# Reading positive words list:\n",
    "with open('positive-words.txt', 'r', encoding = \"ISO-8859-1\") as t:\n",
    "    pos = t.readlines()\n",
    "    pos_words = []\n",
    "    for i in pos:\n",
    "        pos_words.append(i.strip())\n",
    "    del pos_words[0 : 30]\n",
    "    \n",
    "positive_emojis = ['üòÇ','üî•','üòç','ü§ò','ü§©','üëç','üíØ','üòé','‚úÖ','üëè','üòÄ','üêê',\n",
    "                   '‚ù§Ô∏è','‚ô•Ô∏è','üòò','üòä','üòÑ','üòÉ','üòÜ','üòã','ü§™','üòú','üòõ','ü§ë']\n",
    "negative_emojis = ['ü•¥','ü§¢','ü§Æ','üòß','üòë','üò∞','ü§¨','üò°','üò≠','üò¢','üò©','üôÅ',\n",
    "                   '‚òπÔ∏è','üò£','üòñ','üò´','üòü','üòû','üòî','üòí','üëø','ü§ï','ü§í','üò∑']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to count sentiment words in Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count negative words in tweet:\n",
    "def count_negative(tweet):\n",
    "    neg_word_count = 0\n",
    "    for word in tweet:\n",
    "        if word in neg_words:\n",
    "            neg_word_count = neg_word_count + 1\n",
    "            # mg['neg_word_count'] = mg['text'].apply(lambda x: neg_word_count(x), axis = 1, result_type = 'expand')\n",
    "    return neg_word_count\n",
    "   \n",
    "# Function to count positive words in tweet:\n",
    "def count_positive(tweet):\n",
    "    pos_word_count = 0\n",
    "    for word in tweet:\n",
    "        #print(word)\n",
    "        if word in pos_words:\n",
    "            pos_word_count = pos_word_count + 1\n",
    "            # mg['neg_word_count'] = mg['text'].apply(lambda x: neg_word_count(x), axis = 1, result_type = 'expand')\n",
    "    return pos_word_count\n",
    "   \n",
    "def count_mentions(tweet):\n",
    "    num_mentions = 0\n",
    "    for word in tweet:\n",
    "        if word.startswith('@'):\n",
    "            num_mentions = num_mentions + 1\n",
    "    return num_mentions\n",
    "\n",
    "def count_hashtags(tweet):\n",
    "    num_hashtags = 0\n",
    "    for word in tweet:\n",
    "        if word.startswith('#'):\n",
    "            num_hashtags = num_hashtags + 1\n",
    "    return num_hashtags\n",
    "\n",
    "def count_positive_emojis(tweet):\n",
    "    pos_emoji_count = 0\n",
    "    for word in tweet:\n",
    "        #print(word)\n",
    "        if word in positive_emojis:\n",
    "            pos_emoji_count = pos_emoji_count + 1\n",
    "            # mg['neg_word_count'] = mg['text'].apply(lambda x: neg_word_count(x), axis = 1, result_type = 'expand')\n",
    "    return pos_emoji_count\n",
    "\n",
    "def count_negative_emojis(tweet):\n",
    "    neg_emoji_count = 0\n",
    "    for word in tweet:\n",
    "        #print(word)\n",
    "        if word in negative_emojis:\n",
    "            neg_emoji_count = neg_emoji_count + 1\n",
    "            # mg['neg_word_count'] = mg['text'].apply(lambda x: neg_word_count(x), axis = 1, result_type = 'expand')\n",
    "    return neg_emoji_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing functions to break tweets into words, emojis, mentions, and hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is the basis of how tokenizing the Tweet will work. Using regex statments, it accounts for emojis, \n",
    "# hashtags, mentions, and more.\n",
    "import re\n",
    " \n",
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    " \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "    \n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    " \n",
    "def tokenize(s):\n",
    "    return tokens_re.findall(s)\n",
    " \n",
    "def preprocess(s, lowercase=False):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# https://www.kaggle.com/kazanova/sentiment140\n",
    "# Download this dataset (~230mb) to your project directory\n",
    "# Once this is done, begin training models\n",
    "\n",
    "# 0 is negative\n",
    "# 2 is neutral\n",
    "# 4 is positive\n",
    "\n",
    "# This dataset does not have any emojis, so we will have to find an alternative way if \n",
    "# we want to evaluate the effects that emojis have on sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cnames = ['sentiment', 'tweet_id', 'created_at', 'mention', 'author', 'text']\n",
    "\n",
    "training_data = pd.read_csv('training.1600000.processed.noemoticon.csv', names = training_cnames, encoding='latin-1')\n",
    "\n",
    "training_data = training_data[['sentiment', 'tweet_id', 'created_at', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# You can use this to slim down the data set.\n",
    "# Loading and manipulating the full dataset takes about 30 minutes\n",
    "# Pulling in 15000 tweets takes ~18 seconds to manipulate and will give a sufficient\n",
    "# training set to use\n",
    "training_data = training_data.sample(15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.19286298751831\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "training_data['tokenized'] = training_data['text'].apply(lambda x: tokenize(x))\n",
    "training_data['pos_words'] = training_data['tokenized'].apply(lambda x: count_positive(x))\n",
    "training_data['neg_words'] = training_data['tokenized'].apply(lambda x: count_negative(x))\n",
    "training_data['num_mentions'] = training_data['tokenized'].apply(lambda x: count_mentions(x))\n",
    "training_data['num_hashtags'] = training_data['tokenized'].apply(lambda x: count_hashtags(x))\n",
    "training_data['num_positive_emojis'] = training_data['tokenized'].apply(lambda x: count_positive_emojis(x))\n",
    "training_data['num_negative_emojis'] = training_data['tokenized'].apply(lambda x: count_negative_emojis(x))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ML Model on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>pos_words</th>\n",
       "      <th>neg_words</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_positive_emojis</th>\n",
       "      <th>num_negative_emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>877522</th>\n",
       "      <td>4</td>\n",
       "      <td>1685006851</td>\n",
       "      <td>Sat May 02 22:44:37 PDT 2009</td>\n",
       "      <td>@fillanypdf thank you, i think i am looking mo...</td>\n",
       "      <td>[@fillanypdf, thank, you, ,, i, think, i, am, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756524</th>\n",
       "      <td>0</td>\n",
       "      <td>2288758323</td>\n",
       "      <td>Mon Jun 22 19:34:49 PDT 2009</td>\n",
       "      <td>Days like today make me crazy no matter what I...</td>\n",
       "      <td>[Days, like, today, make, me, crazy, no, matte...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607307</th>\n",
       "      <td>0</td>\n",
       "      <td>2222912154</td>\n",
       "      <td>Thu Jun 18 07:36:20 PDT 2009</td>\n",
       "      <td>needs every1 to PRAY for me, just went to orde...</td>\n",
       "      <td>[needs, every, 1, to, PRAY, for, me, ,, just, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261966</th>\n",
       "      <td>4</td>\n",
       "      <td>1998735324</td>\n",
       "      <td>Mon Jun 01 19:02:25 PDT 2009</td>\n",
       "      <td>@iEllie The house we're buying has a pond in t...</td>\n",
       "      <td>[@iEllie, The, house, we're, buying, has, a, p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887966</th>\n",
       "      <td>4</td>\n",
       "      <td>1687153078</td>\n",
       "      <td>Sun May 03 07:55:15 PDT 2009</td>\n",
       "      <td>just woke up to a big pile of puppy shit  good...</td>\n",
       "      <td>[just, woke, up, to, a, big, pile, of, puppy, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693727</th>\n",
       "      <td>0</td>\n",
       "      <td>2252808073</td>\n",
       "      <td>Sat Jun 20 07:02:15 PDT 2009</td>\n",
       "      <td>@piiyaahn Yeah but I'm using it everyday so pe...</td>\n",
       "      <td>[@piiyaahn, Yeah, but, I'm, using, it, everyda...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576987</th>\n",
       "      <td>4</td>\n",
       "      <td>2189617539</td>\n",
       "      <td>Tue Jun 16 00:28:11 PDT 2009</td>\n",
       "      <td>@vampirefreak101 sorry to hear that I feel you...</td>\n",
       "      <td>[@vampirefreak101, sorry, to, hear, that, I, f...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974181</th>\n",
       "      <td>4</td>\n",
       "      <td>1833357034</td>\n",
       "      <td>Sun May 17 23:02:13 PDT 2009</td>\n",
       "      <td>Watched Star Trek the movie yesterday. WOOHOO!...</td>\n",
       "      <td>[Watched, Star, Trek, the, movie, yesterday, ....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161742</th>\n",
       "      <td>0</td>\n",
       "      <td>1957387521</td>\n",
       "      <td>Fri May 29 00:20:42 PDT 2009</td>\n",
       "      <td>@106jackfm I'm not that's why I'm sulking  not...</td>\n",
       "      <td>[@106jackfm, I'm, not, that's, why, I'm, sulki...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527562</th>\n",
       "      <td>4</td>\n",
       "      <td>2177214245</td>\n",
       "      <td>Mon Jun 15 05:41:05 PDT 2009</td>\n",
       "      <td>Hoping A/C gets fixed today.. Oh and hoping I ...</td>\n",
       "      <td>[Hoping, A, /, C, gets, fixed, today, ., ., Oh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment    tweet_id                    created_at  \\\n",
       "877522           4  1685006851  Sat May 02 22:44:37 PDT 2009   \n",
       "756524           0  2288758323  Mon Jun 22 19:34:49 PDT 2009   \n",
       "607307           0  2222912154  Thu Jun 18 07:36:20 PDT 2009   \n",
       "1261966          4  1998735324  Mon Jun 01 19:02:25 PDT 2009   \n",
       "887966           4  1687153078  Sun May 03 07:55:15 PDT 2009   \n",
       "...            ...         ...                           ...   \n",
       "693727           0  2252808073  Sat Jun 20 07:02:15 PDT 2009   \n",
       "1576987          4  2189617539  Tue Jun 16 00:28:11 PDT 2009   \n",
       "974181           4  1833357034  Sun May 17 23:02:13 PDT 2009   \n",
       "161742           0  1957387521  Fri May 29 00:20:42 PDT 2009   \n",
       "1527562          4  2177214245  Mon Jun 15 05:41:05 PDT 2009   \n",
       "\n",
       "                                                      text  \\\n",
       "877522   @fillanypdf thank you, i think i am looking mo...   \n",
       "756524   Days like today make me crazy no matter what I...   \n",
       "607307   needs every1 to PRAY for me, just went to orde...   \n",
       "1261966  @iEllie The house we're buying has a pond in t...   \n",
       "887966   just woke up to a big pile of puppy shit  good...   \n",
       "...                                                    ...   \n",
       "693727   @piiyaahn Yeah but I'm using it everyday so pe...   \n",
       "1576987  @vampirefreak101 sorry to hear that I feel you...   \n",
       "974181   Watched Star Trek the movie yesterday. WOOHOO!...   \n",
       "161742   @106jackfm I'm not that's why I'm sulking  not...   \n",
       "1527562  Hoping A/C gets fixed today.. Oh and hoping I ...   \n",
       "\n",
       "                                                 tokenized  pos_words  \\\n",
       "877522   [@fillanypdf, thank, you, ,, i, think, i, am, ...          1   \n",
       "756524   [Days, like, today, make, me, crazy, no, matte...          2   \n",
       "607307   [needs, every, 1, to, PRAY, for, me, ,, just, ...          1   \n",
       "1261966  [@iEllie, The, house, we're, buying, has, a, p...          0   \n",
       "887966   [just, woke, up, to, a, big, pile, of, puppy, ...          1   \n",
       "...                                                    ...        ...   \n",
       "693727   [@piiyaahn, Yeah, but, I'm, using, it, everyda...          0   \n",
       "1576987  [@vampirefreak101, sorry, to, hear, that, I, f...          1   \n",
       "974181   [Watched, Star, Trek, the, movie, yesterday, ....          0   \n",
       "161742   [@106jackfm, I'm, not, that's, why, I'm, sulki...          1   \n",
       "1527562  [Hoping, A, /, C, gets, fixed, today, ., ., Oh...          0   \n",
       "\n",
       "         neg_words  num_mentions  num_hashtags  num_positive_emojis  \\\n",
       "877522           0             1             0                    0   \n",
       "756524           1             0             0                    0   \n",
       "607307           0             0             0                    0   \n",
       "1261966          0             1             0                    0   \n",
       "887966           1             0             0                    0   \n",
       "...            ...           ...           ...                  ...   \n",
       "693727           0             1             0                    0   \n",
       "1576987          2             1             0                    0   \n",
       "974181           0             0             0                    0   \n",
       "161742           0             1             0                    0   \n",
       "1527562          0             0             0                    0   \n",
       "\n",
       "         num_negative_emojis  \n",
       "877522                     0  \n",
       "756524                     0  \n",
       "607307                     0  \n",
       "1261966                    0  \n",
       "887966                     0  \n",
       "...                      ...  \n",
       "693727                     0  \n",
       "1576987                    0  \n",
       "974181                     0  \n",
       "161742                     0  \n",
       "1527562                    0  \n",
       "\n",
       "[15000 rows x 11 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Twitter API Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = cfg.get(\"TwitterAPI\").get(\"consumer_key\")\n",
    "consumer_secret = cfg.get(\"TwitterAPI\").get(\"consumer_secret\")\n",
    "access_token = cfg.get(\"TwitterAPI\").get(\"access_token\")\n",
    "access_token_secret = cfg.get(\"TwitterAPI\").get(\"access_token_secret\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    " \n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Tweets by User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently limited to num_tweets Tweets\n",
    "column_names = ['tweet_id', 'text','favorite_count','retweet_count','created_at']\n",
    "def get_tweets_by_user(user, tweets):\n",
    "    tweet_json = pd.DataFrame(columns=column_names)\n",
    "    for i in range(math.ceil(tweets/20)):\n",
    "        tweets = api.user_timeline(user, page=i)\n",
    "#         print(str(i) + \"WABBADABBADO\\n\")\n",
    "#         print(tweets)\n",
    "        my_list_of_dicts = []\n",
    "        for each_json_tweet in tweets:\n",
    "            my_list_of_dicts.append(each_json_tweet._json)\n",
    "        filename = user + '.txt'\n",
    "        if os.path.exists(filename):\n",
    "            os.remove(filename)\n",
    "        with open(filename, 'w') as file:\n",
    "            file.write(json.dumps(my_list_of_dicts, indent=4))\n",
    "        my_demo_list = []\n",
    "        with open(filename, encoding='utf-8') as json_file:  \n",
    "            all_data = json.load(json_file)\n",
    "            for each_dictionary in all_data:\n",
    "                tweet_id = each_dictionary['id']\n",
    "                text = each_dictionary['text']\n",
    "                favorite_count = each_dictionary['favorite_count']\n",
    "                retweet_count = each_dictionary['retweet_count']\n",
    "                created_at = each_dictionary['created_at']\n",
    "                my_demo_list.append({'tweet_id': str(tweet_id),\n",
    "                                     'text': str(text),\n",
    "                                     'favorite_count': int(favorite_count),\n",
    "                                     'retweet_count': int(retweet_count),\n",
    "                                     'created_at': created_at,\n",
    "                                    })\n",
    "                #print(my_demo_list)\n",
    "                temp_json = pd.DataFrame(my_demo_list, columns = \n",
    "                                          ['tweet_id', 'text', \n",
    "                                           'favorite_count', 'retweet_count', \n",
    "                                           'created_at'])\n",
    "#             print(\"\\n \\n \" + str(temp_json.shape) + str(type(temp_json)) + \"\\n\\n\")\n",
    "        tweet_json = tweet_json.append(temp_json, ignore_index=True)\n",
    "#         print(\"\\n \\n \" + str(tweet_json.shape) + str(type(tweet_json)) + \"\\n\\n\")\n",
    "    tweet_json = tweet_json.drop_duplicates()    \n",
    "    return tweet_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Tweets by Hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_tweets = get_tweets_by_user('CycloneLarry69', 109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1467591782607343624</td>\n",
       "      <td>@GACyclone91 The SEC scan lick my butt and I d...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Dec 05 20:28:42 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1467591477496848388</td>\n",
       "      <td>What a time to be alive https://t.co/i3bevycYtV</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Dec 05 20:27:29 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1467591379266293768</td>\n",
       "      <td>The drunk game watch in Florida for the #5 Cyc...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Dec 05 20:27:06 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1467591161074360322</td>\n",
       "      <td>I think I‚Äôm actually going to cheer for Iowa a...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Dec 05 20:26:13 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1467590241917849600</td>\n",
       "      <td>@baylortk Yes sir</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Dec 05 20:22:34 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1467229885202632705</td>\n",
       "      <td>@RJHINDM Or force a turnover I guess</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sat Dec 04 20:30:39 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1467229697780109323</td>\n",
       "      <td>@RJHINDM Have to</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sat Dec 04 20:29:54 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1467229585620275210</td>\n",
       "      <td>Oh man that‚Äôs a brutal call</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Sat Dec 04 20:29:27 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1467227767049797637</td>\n",
       "      <td>Ain‚Äôt no way lol</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Sat Dec 04 20:22:14 +0000 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>1467223995317727234</td>\n",
       "      <td>Football is simply better outdoors especially ...</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>Sat Dec 04 20:07:14 +0000 2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id                                               text  \\\n",
       "0    1467591782607343624  @GACyclone91 The SEC scan lick my butt and I d...   \n",
       "1    1467591477496848388    What a time to be alive https://t.co/i3bevycYtV   \n",
       "2    1467591379266293768  The drunk game watch in Florida for the #5 Cyc...   \n",
       "3    1467591161074360322  I think I‚Äôm actually going to cheer for Iowa a...   \n",
       "4    1467590241917849600                                  @baylortk Yes sir   \n",
       "..                   ...                                                ...   \n",
       "115  1467229885202632705               @RJHINDM Or force a turnover I guess   \n",
       "116  1467229697780109323                                   @RJHINDM Have to   \n",
       "117  1467229585620275210                        Oh man that‚Äôs a brutal call   \n",
       "118  1467227767049797637                                   Ain‚Äôt no way lol   \n",
       "119  1467223995317727234  Football is simply better outdoors especially ...   \n",
       "\n",
       "    favorite_count retweet_count                      created_at  \n",
       "0                2             0  Sun Dec 05 20:28:42 +0000 2021  \n",
       "1               22             0  Sun Dec 05 20:27:29 +0000 2021  \n",
       "2                7             0  Sun Dec 05 20:27:06 +0000 2021  \n",
       "3               10             0  Sun Dec 05 20:26:13 +0000 2021  \n",
       "4                1             0  Sun Dec 05 20:22:34 +0000 2021  \n",
       "..             ...           ...                             ...  \n",
       "115              0             0  Sat Dec 04 20:30:39 +0000 2021  \n",
       "116              0             0  Sat Dec 04 20:29:54 +0000 2021  \n",
       "117              9             1  Sat Dec 04 20:29:27 +0000 2021  \n",
       "118              9             0  Sat Dec 04 20:22:14 +0000 2021  \n",
       "119             40             1  Sat Dec 04 20:07:14 +0000 2021  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tweets['tokenized'] = user_tweets['text'].apply(lambda x: tokenize(x))\n",
    "user_tweets['pos_words'] = user_tweets['tokenized'].apply(lambda x: count_positive(x))\n",
    "user_tweets['neg_words'] = user_tweets['tokenized'].apply(lambda x: count_negative(x))\n",
    "user_tweets['num_mentions'] = user_tweets['tokenized'].apply(lambda x: count_mentions(x))\n",
    "user_tweets['num_hashtags'] = user_tweets['tokenized'].apply(lambda x: count_hashtags(x))\n",
    "user_tweets['num_positive_emojis'] = user_tweets['tokenized'].apply(lambda x: count_positive_emojis(x))\n",
    "user_tweets['num_negative_emojis'] = user_tweets['tokenized'].apply(lambda x: count_negative_emojis(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>pos_words</th>\n",
       "      <th>neg_words</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_positive_emojis</th>\n",
       "      <th>num_negative_emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1467591782607343624</td>\n",
       "      <td>@GACyclone91 The SEC scan lick my butt and I d...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Dec 05 20:28:42 +0000 2021</td>\n",
       "      <td>[@GACyclone91, The, SEC, scan, lick, my, butt,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1467591477496848388</td>\n",
       "      <td>What a time to be alive https://t.co/i3bevycYtV</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Dec 05 20:27:29 +0000 2021</td>\n",
       "      <td>[What, a, time, to, be, alive, https://t.co/i3...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1467591379266293768</td>\n",
       "      <td>The drunk game watch in Florida for the #5 Cyc...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Dec 05 20:27:06 +0000 2021</td>\n",
       "      <td>[The, drunk, game, watch, in, Florida, for, th...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1467591161074360322</td>\n",
       "      <td>I think I‚Äôm actually going to cheer for Iowa a...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Dec 05 20:26:13 +0000 2021</td>\n",
       "      <td>[I, think, I, ‚Äô, m, actually, going, to, cheer...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1467590241917849600</td>\n",
       "      <td>@baylortk Yes sir</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Dec 05 20:22:34 +0000 2021</td>\n",
       "      <td>[@baylortk, Yes, sir]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1467229885202632705</td>\n",
       "      <td>@RJHINDM Or force a turnover I guess</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sat Dec 04 20:30:39 +0000 2021</td>\n",
       "      <td>[@RJHINDM, Or, force, a, turnover, I, guess]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1467229697780109323</td>\n",
       "      <td>@RJHINDM Have to</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sat Dec 04 20:29:54 +0000 2021</td>\n",
       "      <td>[@RJHINDM, Have, to]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1467229585620275210</td>\n",
       "      <td>Oh man that‚Äôs a brutal call</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Sat Dec 04 20:29:27 +0000 2021</td>\n",
       "      <td>[Oh, man, that, ‚Äô, s, a, brutal, call]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1467227767049797637</td>\n",
       "      <td>Ain‚Äôt no way lol</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Sat Dec 04 20:22:14 +0000 2021</td>\n",
       "      <td>[Ain, ‚Äô, t, no, way, lol]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>1467223995317727234</td>\n",
       "      <td>Football is simply better outdoors especially ...</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>Sat Dec 04 20:07:14 +0000 2021</td>\n",
       "      <td>[Football, is, simply, better, outdoors, espec...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id                                               text  \\\n",
       "0    1467591782607343624  @GACyclone91 The SEC scan lick my butt and I d...   \n",
       "1    1467591477496848388    What a time to be alive https://t.co/i3bevycYtV   \n",
       "2    1467591379266293768  The drunk game watch in Florida for the #5 Cyc...   \n",
       "3    1467591161074360322  I think I‚Äôm actually going to cheer for Iowa a...   \n",
       "4    1467590241917849600                                  @baylortk Yes sir   \n",
       "..                   ...                                                ...   \n",
       "115  1467229885202632705               @RJHINDM Or force a turnover I guess   \n",
       "116  1467229697780109323                                   @RJHINDM Have to   \n",
       "117  1467229585620275210                        Oh man that‚Äôs a brutal call   \n",
       "118  1467227767049797637                                   Ain‚Äôt no way lol   \n",
       "119  1467223995317727234  Football is simply better outdoors especially ...   \n",
       "\n",
       "    favorite_count retweet_count                      created_at  \\\n",
       "0                2             0  Sun Dec 05 20:28:42 +0000 2021   \n",
       "1               22             0  Sun Dec 05 20:27:29 +0000 2021   \n",
       "2                7             0  Sun Dec 05 20:27:06 +0000 2021   \n",
       "3               10             0  Sun Dec 05 20:26:13 +0000 2021   \n",
       "4                1             0  Sun Dec 05 20:22:34 +0000 2021   \n",
       "..             ...           ...                             ...   \n",
       "115              0             0  Sat Dec 04 20:30:39 +0000 2021   \n",
       "116              0             0  Sat Dec 04 20:29:54 +0000 2021   \n",
       "117              9             1  Sat Dec 04 20:29:27 +0000 2021   \n",
       "118              9             0  Sat Dec 04 20:22:14 +0000 2021   \n",
       "119             40             1  Sat Dec 04 20:07:14 +0000 2021   \n",
       "\n",
       "                                             tokenized  pos_words  neg_words  \\\n",
       "0    [@GACyclone91, The, SEC, scan, lick, my, butt,...          1          0   \n",
       "1    [What, a, time, to, be, alive, https://t.co/i3...          0          0   \n",
       "2    [The, drunk, game, watch, in, Florida, for, th...          1          1   \n",
       "3    [I, think, I, ‚Äô, m, actually, going, to, cheer...          1          0   \n",
       "4                                [@baylortk, Yes, sir]          0          0   \n",
       "..                                                 ...        ...        ...   \n",
       "115       [@RJHINDM, Or, force, a, turnover, I, guess]          0          0   \n",
       "116                               [@RJHINDM, Have, to]          0          0   \n",
       "117             [Oh, man, that, ‚Äô, s, a, brutal, call]          0          1   \n",
       "118                          [Ain, ‚Äô, t, no, way, lol]          0          0   \n",
       "119  [Football, is, simply, better, outdoors, espec...          1          1   \n",
       "\n",
       "     num_mentions  num_hashtags  num_positive_emojis  num_negative_emojis  \n",
       "0               1             0                    0                    0  \n",
       "1               0             0                    0                    0  \n",
       "2               0             2                    0                    0  \n",
       "3               0             0                    0                    0  \n",
       "4               1             0                    0                    0  \n",
       "..            ...           ...                  ...                  ...  \n",
       "115             1             0                    0                    0  \n",
       "116             1             0                    0                    0  \n",
       "117             0             0                    0                    0  \n",
       "118             0             0                    0                    0  \n",
       "119             0             0                    0                    0  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# punctuation = list(string.punctuation)\n",
    "# stop = stopwords.words('english') + punctuation + ['rt', 'via', '‚Äô', 'RT', 'Ô∏è', '‚Ä¶']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count_all = Counter()\n",
    "# for tweet in user_tweets['text']:\n",
    "#     terms_all = [term for term in preprocess(tweet)]\n",
    "#     terms_stop = [term for term in preprocess(tweet) if term not in stop]\n",
    "#     count_all.update(terms_stop)\n",
    "#     print(tweet + \"\\n\")\n",
    "# print(count_all.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
